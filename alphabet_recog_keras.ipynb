{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Banipreet\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPooling2D, Input, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('A_Z Handwritten Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:,0].values\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.027, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(362393, 784)\n",
      "(10057, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24b4fbf3c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtest = X_train[2]\n",
    "xtest = xtest.reshape([28,28])\n",
    "ytest = y_train[2]\n",
    "plt.imshow(xtest)\n",
    "print(chr(ord('A')+ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(362393, 26)\n"
     ]
    }
   ],
   "source": [
    "num_classes= 26\n",
    "input_shape = (28,28,1)\n",
    "X_train = np.reshape(X_train, [X_train.shape[0],28,28,1])\n",
    "X_test = np.reshape(X_test, [X_test.shape[0],28,28,1])\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphaModel(input_shape = (28, 28, 1)):\n",
    "    X_input = Input(input_shape)\n",
    "    X = Conv2D(filters = 32, kernel_size = (5, 5), strides = (1,1), padding = 'same',activation='relu')(X_input)\n",
    "    X = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='valid')(X)\n",
    "\n",
    "    X = Conv2D(filters = 64, kernel_size = (5,5), strides = (1,1), padding = 'same', activation='relu')(X)\n",
    "    X = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='valid')(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1024, activation='relu', kernel_initializer='TruncatedNormal',bias_initializer='zeros')(X)\n",
    "    X = Dense(num_classes, activation='softmax', kernel_initializer='TruncatedNormal',bias_initializer='zeros')(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='alphaModel')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 26)                26650     \n",
      "=================================================================\n",
      "Total params: 3,291,034\n",
      "Trainable params: 3,291,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = alphaModel(input_shape = (28,28,1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 362393 samples, validate on 10057 samples\n",
      "Epoch 1/10\n",
      "362393/362393 [==============================] - 54s - loss: 0.1535 - acc: 0.9571 - val_loss: 0.0647 - val_acc: 0.9829\n",
      "Epoch 2/10\n",
      "362393/362393 [==============================] - 56s - loss: 0.0449 - acc: 0.9872 - val_loss: 0.0455 - val_acc: 0.9876\n",
      "Epoch 3/10\n",
      "362393/362393 [==============================] - 51s - loss: 0.0291 - acc: 0.9915 - val_loss: 0.0414 - val_acc: 0.9900\n",
      "Epoch 4/10\n",
      "362393/362393 [==============================] - 51s - loss: 0.0199 - acc: 0.9937 - val_loss: 0.0345 - val_acc: 0.9908\n",
      "Epoch 5/10\n",
      "362393/362393 [==============================] - 50s - loss: 0.0141 - acc: 0.9954 - val_loss: 0.0273 - val_acc: 0.9931\n",
      "Epoch 6/10\n",
      "362393/362393 [==============================] - 51s - loss: 0.0109 - acc: 0.9964 - val_loss: 0.0294 - val_acc: 0.9925\n",
      "Epoch 7/10\n",
      "362393/362393 [==============================] - 51s - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0204 - val_acc: 0.9950\n",
      "Epoch 8/10\n",
      "362393/362393 [==============================] - 51s - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0228 - val_acc: 0.9953\n",
      "Epoch 9/10\n",
      "362393/362393 [==============================] - 51s - loss: 0.0063 - acc: 0.9979 - val_loss: 0.0247 - val_acc: 0.9949\n",
      "Epoch 10/10\n",
      "362393/362393 [==============================] - 51s - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0196 - val_acc: 0.9962\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "hist = model.fit(X_train, y_train,\n",
    "          batch_size=512,\n",
    "          epochs=10,\n",
    "          validation_data=(X_test, y_test), \n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights to file\n",
    "model.save_weights(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights from file (can call without model.fit)\n",
    "model.load_weights(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362393/362393 [==============================] - 83s    \n",
      "Train Accuracy: 99.80408010073693%\n",
      "Test Accuracy: 99.62215372377449%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "score2 = model.evaluate(X_train, y_train)\n",
    "print(\"Train Accuracy: \"+str(score2[1]*100)+\"%\")\n",
    "print(\"Test Accuracy: \"+str(score[1]*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(glob(\"Alphabets/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24b4fbf3780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(len(test), 1))\n",
    "ctr = 1\n",
    "b = []\n",
    "for img_path in test:\n",
    "    img = cv2.imread(img_path)\n",
    "    fig.add_subplot(len(test), 1, ctr)\n",
    "    plt.imshow(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    (thresh, im_bw) = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    b.append(im_bw)\n",
    "    ctr += 1\n",
    "    \n",
    "    \n",
    "b = np.array(b)\n",
    "b = np.reshape(b, [b.shape[0],b.shape[1],b.shape[2],1])\n",
    "b = model.predict(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "for ans in b:\n",
    "    temp = np.argmax(ans)\n",
    "    print(chr(ord('A')+temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
